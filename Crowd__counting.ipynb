{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Crowd _counting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1dXG99P60LpMenNkxeVTIbUhkI-1l5_cR",
      "authorship_tag": "ABX9TyOG9yPqPBivgt/7+beVxThh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nganninh/Ngan/blob/main/Crowd__counting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKls7Am0QZ-A",
        "outputId": "00cff1df-30e6-4ff0-e4c6-6528fb08ea79"
      },
      "source": [
        "!git clone https://github.com/leeyeehoo/CSRNet-pytorch.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CSRNet-pytorch'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Total 86 (delta 0), reused 0 (delta 0), pack-reused 86\u001b[K\n",
            "Unpacking objects: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_DPXJ-9S8uy",
        "outputId": "bf5c09ec-6b6a-48f7-cc8d-521140991297"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0CuT-23UJj1"
      },
      "source": [
        "!cd CSRNet-pytorch/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "kkQFDBCJROcR",
        "outputId": "f26bd5cb-f489-4274-df32-9ff360dfb879"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torchvision import models\n",
        "from utils import save_net,load_net"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-68377fd108bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mCrowd_counting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mload_net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Crowd_counting'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfcGhXQARP-l"
      },
      "source": [
        "class CSRNet(nn.Module):\n",
        "    def __init__(self, load_weights=False):\n",
        "        super(CSRNet, self).__init__()\n",
        "        self.frontend_feat = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512]\n",
        "        self.backend_feat  = [512, 512, 512,256,128,64]\n",
        "        self.frontend = make_layers(self.frontend_feat)\n",
        "        self.backend = make_layers(self.backend_feat,in_channels = 512,dilation = True)\n",
        "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
        "        if not load_weights:\n",
        "            mod = models.vgg16(pretrained = True)\n",
        "            self._initialize_weights()\n",
        "            for i in xrange(len(self.frontend.state_dict().items())):\n",
        "                self.frontend.state_dict().items()[i][1].data[:] = mod.state_dict().items()[i][1].data[:]\n",
        "    def forward(self,x):\n",
        "        x = self.frontend(x)\n",
        "        x = self.backend(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.normal_(m.weight, 0.01)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RoXFHb9RP3z"
      },
      "source": [
        "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
        "    if dilation:\n",
        "        d_rate = 2\n",
        "    else:\n",
        "        d_rate = 1\n",
        "    layers = []\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate,dilation = d_rate)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAzFkh9cRVVh"
      },
      "source": [
        "model = CSRNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rCIyMoZRXvp"
      },
      "source": [
        "x = torch.rand((1,3,255,255))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIsvHfgERX2p"
      },
      "source": [
        "model(x).shape\n",
        "Execution output\n",
        "\ttext/plain\n",
        "\t\ttorch.Size([1, 1, 31, 31])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxKIQ6VCRckZ"
      },
      "source": [
        "Make dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0kNeUARRX5T"
      },
      "source": [
        "import h5py\n",
        "import scipy.io as io\n",
        "import PIL.Image as Image\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.ndimage.filters import gaussian_filter \n",
        "import scipy\n",
        "import json\n",
        "from matplotlib import cm as CM\n",
        "from image import *\n",
        "from model import CSRNet\n",
        "import torch\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBIJA0n0RYDd"
      },
      "source": [
        "def gaussian_filter_density(gt):\n",
        "    print gt.shape\n",
        "    density = np.zeros(gt.shape, dtype=np.float32)\n",
        "    gt_count = np.count_nonzero(gt)\n",
        "    if gt_count == 0:\n",
        "        return density\n",
        "\n",
        "    pts = np.array(zip(np.nonzero(gt)[1], np.nonzero(gt)[0]))\n",
        "    leafsize = 2048\n",
        "    # build kdtree\n",
        "    tree = scipy.spatial.KDTree(pts.copy(), leafsize=leafsize)\n",
        "    # query kdtree\n",
        "    distances, locations = tree.query(pts, k=4)\n",
        "\n",
        "    print 'generate density...'\n",
        "    for i, pt in enumerate(pts):\n",
        "        pt2d = np.zeros(gt.shape, dtype=np.float32)\n",
        "        pt2d[pt[1],pt[0]] = 1.\n",
        "        if gt_count > 1:\n",
        "            sigma = (distances[i][1]+distances[i][2]+distances[i][3])*0.1\n",
        "        else:\n",
        "            sigma = np.average(np.array(gt.shape))/2./2. #case: 1 point\n",
        "        density += scipy.ndimage.filters.gaussian_filter(pt2d, sigma, mode='constant')\n",
        "    print 'done.'\n",
        "    return density"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnzhGPULRk9q"
      },
      "source": [
        "root = '/home/leeyh/Downloads/Shanghai/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "328G3npxRlAU"
      },
      "source": [
        "part_A_train = os.path.join(root,'part_A_final/train_data','images')\n",
        "part_A_test = os.path.join(root,'part_A_final/test_data','images')\n",
        "part_B_train = os.path.join(root,'part_B_final/train_data','images')\n",
        "part_B_test = os.path.join(root,'part_B_final/test_data','images')\n",
        "path_sets = [part_A_train,part_A_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbklAsWxRpgz"
      },
      "source": [
        "img_paths = []\n",
        "for path in path_sets:\n",
        "    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n",
        "        img_paths.append(img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrjwIm6jRrhn"
      },
      "source": [
        "for img_path in img_paths:\n",
        "    print img_path\n",
        "    mat = io.loadmat(img_path.replace('.jpg','.mat').replace('images','ground_truth').replace('IMG_','GT_IMG_'))\n",
        "    img= plt.imread(img_path)\n",
        "    k = np.zeros((img.shape[0],img.shape[1]))\n",
        "    gt = mat[\"image_info\"][0,0][0,0][0]\n",
        "    for i in range(0,len(gt)):\n",
        "        if int(gt[i][1])<img.shape[0] and int(gt[i][0])<img.shape[1]:\n",
        "            k[int(gt[i][1]),int(gt[i][0])]=1\n",
        "    k = gaussian_filter_density(k)\n",
        "    with h5py.File(img_path.replace('.jpg','.h5').replace('images','ground_truth'), 'w') as hf:\n",
        "            hf['density'] = k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHRItKWdRrnV"
      },
      "source": [
        "plt.imshow(Image.open(img_paths[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKERnUBURuMw"
      },
      "source": [
        "gt_file = h5py.File(img_paths[0].replace('.jpg','.h5').replace('images','ground_truth'),'r')\n",
        "groundtruth = np.asarray(gt_file['density'])\n",
        "plt.imshow(groundtruth,cmap=CM.jet)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8pGdjNPRuPg"
      },
      "source": [
        "np.sum(groundtruth)# don't mind this slight variation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "How7c7X_RuTS"
      },
      "source": [
        "path_sets = [part_B_train,part_B_test]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE5vvggBRuYz"
      },
      "source": [
        "img_paths = []\n",
        "for path in path_sets:\n",
        "    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n",
        "        img_paths.append(img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ML-JFnSRudF"
      },
      "source": [
        "for img_path in img_paths:\n",
        "    print img_path\n",
        "    mat = io.loadmat(img_path.replace('.jpg','.mat').replace('images','ground_truth').replace('IMG_','GT_IMG_'))\n",
        "    img= plt.imread(img_path)\n",
        "    k = np.zeros((img.shape[0],img.shape[1]))\n",
        "    gt = mat[\"image_info\"][0,0][0,0][0]\n",
        "    for i in range(0,len(gt)):\n",
        "        if int(gt[i][1])<img.shape[0] and int(gt[i][0])<img.shape[1]:\n",
        "            k[int(gt[i][1]),int(gt[i][0])]=1\n",
        "    k = gaussian_filter(k,15)\n",
        "    with h5py.File(img_path.replace('.jpg','.h5').replace('images','ground_truth'), 'w') as hf:\n",
        "            hf['density'] = k"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}